{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 導入函式庫\n",
    "import numpy as np  \n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils  # 用來後續將 label 標籤轉為 one-hot-encoding  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 載入 MNIST 資料庫的訓練資料，並自動分為『訓練組』及『測試組』\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 建立簡單的線性執行的模型\n",
    "# model = Sequential()\n",
    "# # Add Input layer, 隱藏層(hidden layer) 有 256個輸出變數\n",
    "# model.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu')) \n",
    "# # Add output layer\n",
    "# model.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# # 編譯: 選擇損失函數、優化方法及成效衡量方式\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# # 將 training 的 label 進行 one-hot encoding，例如數字 7 經過 One-hot encoding 轉換後是 0000001000，即第7個值為 1\n",
    "# y_TrainOneHot = np_utils.to_categorical(y_train) \n",
    "# y_TestOneHot = np_utils.to_categorical(y_test) \n",
    "\n",
    "# # 將 training 的 input 資料轉為2維\n",
    "# X_train_2D = X_train.reshape(60000, 28*28).astype('float32')  \n",
    "# X_test_2D = X_test.reshape(10000, 28*28).astype('float32')  \n",
    "\n",
    "# x_Train_norm = X_train_2D/255\n",
    "# x_Test_norm = X_test_2D/255\n",
    "\n",
    "# # 進行訓練, 訓練過程會存在 train_history 變數中\n",
    "# train_history = model.fit(x=x_Train_norm, y=y_TrainOneHot, validation_split=0.2, epochs=10, batch_size=800, verbose=2)  \n",
    "\n",
    "# # 顯示訓練成果(分數)\n",
    "# scores = model.evaluate(x_Test_norm, y_TestOneHot)  \n",
    "# print()  \n",
    "# print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(scores[1]*100.0))  \n",
    "\n",
    "# # 預測(prediction)\n",
    "# X = x_Test_norm[0:10,:]\n",
    "# predictions = model.predict_classes(X)\n",
    "# # get prediction result\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 94,533\n",
      "Trainable params: 94,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 64x64 -> 32x32\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), strides=2, activation='relu', padding='same'))\n",
    "\n",
    "# 32x32 -> 16x16\n",
    "#model.add(Conv2D(16, (1, 1), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), strides=2, activation='relu', padding='same'))\n",
    "\n",
    "# 16x16 -> 8x8\n",
    "#model.add(Conv2D(32, (1, 1), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), strides=2, activation='relu', padding='same'))\n",
    "\n",
    "# 8x8 -> 4x4\n",
    "#model.add(Conv2D(32, (1, 1), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), strides=2, activation='relu', padding='same'))\n",
    "\n",
    "# 4x4 -> 1x1\n",
    "model.add(keras.layers.pooling.AveragePooling2D(pool_size=(2,2)))\n",
    "\n",
    "# flatten and fc\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "#adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 471 images belonging to 5 classes.\n",
      "Found 51 images belonging to 5 classes.\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 303s 152ms/step - loss: 1.3614 - acc: 0.3555 - val_loss: 0.6531 - val_acc: 0.7569\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 0.7862 - acc: 0.6977 - val_loss: 0.4428 - val_acc: 0.8431\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.5870 - acc: 0.7835 - val_loss: 0.4979 - val_acc: 0.8431\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 0.4170 - acc: 0.8518 - val_loss: 0.3330 - val_acc: 0.8980\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 300s 150ms/step - loss: 0.6449 - acc: 0.7514 - val_loss: 0.6325 - val_acc: 0.7765\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.6045 - acc: 0.7723 - val_loss: 0.1647 - val_acc: 0.9255\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.3879 - acc: 0.8624 - val_loss: 0.1427 - val_acc: 0.9529\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 0.2339 - acc: 0.9195 - val_loss: 0.1768 - val_acc: 0.9451\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 303s 152ms/step - loss: 0.3035 - acc: 0.8959 - val_loss: 0.1656 - val_acc: 0.9451\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 0.3280 - acc: 0.8860 - val_loss: 0.9606 - val_acc: 0.6549\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.2818 - acc: 0.9013 - val_loss: 0.1844 - val_acc: 0.9451\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 304s 152ms/step - loss: 0.2764 - acc: 0.9046 - val_loss: 0.1783 - val_acc: 0.9176\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 303s 152ms/step - loss: 0.3366 - acc: 0.8764 - val_loss: 0.1271 - val_acc: 0.9608\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 301s 150ms/step - loss: 0.1895 - acc: 0.9340 - val_loss: 0.1038 - val_acc: 0.9765\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.1867 - acc: 0.9365 - val_loss: 0.1327 - val_acc: 0.9608\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.1519 - acc: 0.9473 - val_loss: 1.1091 - val_acc: 0.5765\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.1636 - acc: 0.9420 - val_loss: 0.1142 - val_acc: 0.9608\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 0.2205 - acc: 0.9249 - val_loss: 0.1823 - val_acc: 0.9255\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 304s 152ms/step - loss: 0.1580 - acc: 0.9442 - val_loss: 0.1406 - val_acc: 0.9490\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 304s 152ms/step - loss: 0.1269 - acc: 0.9552 - val_loss: 0.1398 - val_acc: 0.9529\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 303s 152ms/step - loss: 0.1862 - acc: 0.9355 - val_loss: 0.1253 - val_acc: 0.9608\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.1491 - acc: 0.9474 - val_loss: 0.0709 - val_acc: 0.9686\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 0.1169 - acc: 0.9592 - val_loss: 0.1014 - val_acc: 0.9804\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.1280 - acc: 0.9550 - val_loss: 0.0640 - val_acc: 0.9843\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 0.1354 - acc: 0.9528 - val_loss: 0.0896 - val_acc: 0.9686\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 300s 150ms/step - loss: 0.1328 - acc: 0.9531 - val_loss: 0.0632 - val_acc: 0.9725\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 303s 151ms/step - loss: 0.1297 - acc: 0.9542 - val_loss: 0.1399 - val_acc: 0.9569\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 12.0983 - acc: 0.2475 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 12.3857 - acc: 0.2316 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 301s 151ms/step - loss: 12.3874 - acc: 0.2315 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 301s 150ms/step - loss: 12.3871 - acc: 0.2315 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 301s 151ms/step - loss: 12.3884 - acc: 0.2314 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 12.3868 - acc: 0.2315 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 301s 150ms/step - loss: 12.3918 - acc: 0.2312 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 301s 151ms/step - loss: 12.3838 - acc: 0.2317 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 301s 151ms/step - loss: 12.3875 - acc: 0.2315 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 12.3945 - acc: 0.2310 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 301s 150ms/step - loss: 12.3834 - acc: 0.2317 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 303s 152ms/step - loss: 12.3848 - acc: 0.2316 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 303s 152ms/step - loss: 12.3892 - acc: 0.2313 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 302s 151ms/step - loss: 12.3859 - acc: 0.2316 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 301s 150ms/step - loss: 12.3902 - acc: 0.2313 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 301s 150ms/step - loss: 12.3916 - acc: 0.2312 - val_loss: 12.3256 - val_acc: 0.2353\n",
      "Epoch 44/200\n",
      " 958/2000 [=============>................] - ETA: 2:39 - loss: 12.3845 - acc: 0.2316"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ac531cfd8a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;31m#         validation_data=validation_generator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#         validation_steps=800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_datagen = ImageDataGenerator(\n",
    "#         rotation_range=180,\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         validation_split = 0.1)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(        \n",
    "#             rotation_range=180,\n",
    "#             rescale=1./255,\n",
    "#             shear_range=0.2,\n",
    "#             zoom_range=0.2,\n",
    "#             horizontal_flip=True,\n",
    "#             validation_split = 0.1\n",
    "# )\n",
    "\n",
    "\n",
    "data_gen = ImageDataGenerator(   \n",
    "        rotation_range=180,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split = 0.1)\n",
    "\n",
    "dir_path = '/Users/huang/Desktop/IDVR_final/TrainTest/train'\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = data_gen.flow_from_directory(dir_path,\n",
    "                                               target_size=(64, 64),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical', subset='training')\n",
    "\n",
    "validation_generator = data_gen.flow_from_directory(dir_path,\n",
    "                                               target_size=(64, 64),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical', subset='validation')\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         '/Users/huang/Desktop/IDVR_final/TrainTest/train',\n",
    "#         target_size=(64, 64),\n",
    "#         batch_size=32,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#         '/Users/huang/Desktop/IDVR_final/TrainTest/validation',\n",
    "#         target_size=(64, 64),\n",
    "#         batch_size=32,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps = 10,\n",
    "        epochs=23,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=800\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'model_ver3.h5'\n",
    "# model.save('/Users/huang/Desktop/IDVR_final/model/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181226\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "count = 1\n",
    "model_name = str(datetime.date.today())\n",
    "model_name = ''.join(filemame.split('-')) + '_ver' + str(count)\n",
    "print(model_name)\n",
    "\n",
    "while(os.path.isfile(model_name)):\n",
    "    count += 1\n",
    "    model_name = model_name[:-1] + str(count)\n",
    "model.save('/Users/huang/Desktop/IDVR_final/model/' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "# model.add(Conv2D(16, (3, 3), input_shape=(64, 64, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "# model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "#model.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu')) \n",
    "\n",
    "# COMPILE\n",
    "# adam = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=adam,\n",
    "#               metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
